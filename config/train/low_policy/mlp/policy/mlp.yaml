target: genrl.policies.low.mlp.nn.MLPBehaviorClone


cfg:
  observation_dim: ${env.observation_dim}
  action_dim: ${env.action_dim}
  subseq_len: ${subseq_len}

  optimizer_class: adam
  lr: 1e-4
  optimizer_kwargs: {}

  policy:
    net_arch:
      - 256
      - 256
      - 256
      - 256
    activation_fn: relu
    output_dim: ${env.action_dim}
    dropout: 0.0
    act_scale: 1.20